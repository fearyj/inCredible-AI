{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73849bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bc9dd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redirecting stdout and stderr to silence the output\n",
    "sys.stdout = open(os.devnull, 'w')\n",
    "sys.stderr = open(os.devnull, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d4bff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open video file\n",
    "video_path = r\"C:\\Users\\jingh\\OneDrive - Nanyang Technological University\\NTU_Computer Science\\techfest_misinf\\photos and vids\\dog and human vid.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "frame_count = 0\n",
    "saved = False  # Flag to check if we captured a frame\n",
    "model = YOLO(\"yolov8n.pt\", verbose=False)  # Use 'yolov8n.pt' for a lightweight model\n",
    "\n",
    "captured_frame = None  # Variable to hold the captured frame\n",
    "\n",
    "while cap.isOpened():\n",
    "    # ret: whether the frame was successfully read \n",
    "    # frame: actual frame content\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Exit if no more frames\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Run YOLO object detection\n",
    "    results = model(frame)\n",
    "\n",
    "    # Check if a person ('class 0' in COCO dataset) is detected\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            if int(box.cls) == 0:  # Class '0' corresponds to 'person'\n",
    "                captured_frame = frame  # Store the captured frame\n",
    "                print(f\"Frame {frame_count} captured with a human!\")\n",
    "                saved = True\n",
    "                break\n",
    "\n",
    "        if saved:\n",
    "            break  # Stop processing once a frame is saved\n",
    "\n",
    "    if saved:\n",
    "        break  # Exit the loop after saving the first frame\n",
    "\n",
    "# Stop the timer and calculate the total time taken\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Time taken to process the video: {total_time:.2f} seconds\")\n",
    "\n",
    "# Step 2: Restore stdout and stderr to normal\n",
    "sys.stdout = sys.__stdout__\n",
    "sys.stderr = sys.__stderr__\n",
    "\n",
    "# Now you can print or output messages normally again\n",
    "print(\"Video processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc117f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Video processing complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
